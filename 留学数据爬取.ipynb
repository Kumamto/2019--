{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 寄托天下论坛留学数据爬取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思路："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先爬取所有offer页面的url，再对网页信息进行分别爬取，网页信息部分分为个人情况和offer汇总两部分分别爬取，以id为键进行连接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分别爬取五个板块的url进行汇总"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以澳洲新西兰留学为例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一.先尝试统一汇总一页的url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "\n",
    "url1='http://bbs.gter.net/forum.php?mod=forumdisplay&fid=128&orderby=dateline&typeid=1464&orderby=dateline&typeid=1464&filter=author&page=1'\n",
    "\n",
    "headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36',\n",
    "         'Cookie':'4B5x_c0ae_saltkey=90SlvSJk; 4B5x_c0ae_lastvisit=1575463715; bdshare_firstime=1575467415257; 4B5x_c0ae_smile=1D1; 4B5x_c0ae_ulastactivity=c423cAryvPp6Pq9L3NT0a9Rs%2BH5i4AEEe9gCuCxa4kSGy%2FvWZibW; VMhOIbxho_search_time=1576065710; _miucms_session=eee6c0622abd29c931709d7191ebe317; _miucms_session_gter=e5f80e0b26c692fa07b955c3857b5d80; Hm_lvt_4bd66cbe45a640b607fe46c48f658746=1576065653,1576077382,1576126419,1576126421; 4B5x_c0ae_sid=tnm4fh; 4B5x_c0ae_fid49=1576120563; 4B5x_c0ae_fid811=1576128945; 4B5x_c0ae_visitedfid=128D811D812D49; 4B5x_c0ae_sendmail=1; 4B5x_c0ae_lastact=1576136681%09forum.php%09forumdisplay; 4B5x_c0ae_forum_lastvisit=D_957_1576063866D_565_1576126441D_486_1576126509D_49_1576136376D_812_1576136386D_811_1576136401D_128_1576136681; Hm_lpvt_4bd66cbe45a640b607fe46c48f658746=1576136688'}\n",
    "\n",
    "req=requests.get(url1,headers=headers)\n",
    "soup=BeautifulSoup(req.text,'lxml')\n",
    "\n",
    "a1=soup.find_all(\"a\",class_=\"xst\")\n",
    "urllist1=[]\n",
    "\n",
    "for a in a1:\n",
    "    urllist1.append(a[\"href\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二.对一个模块进行批量抓取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url='http://bbs.gter.net/forum.php?mod=forumdisplay&fid=128&orderby=dateline&typeid=1464&orderby=dateline&typeid=1464&filter=author&page={}'\n",
    "headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36',\n",
    "         'Cookie':'4B5x_c0ae_saltkey=90SlvSJk; 4B5x_c0ae_lastvisit=1575463715; bdshare_firstime=1575467415257; 4B5x_c0ae_smile=1D1; 4B5x_c0ae_ulastactivity=c423cAryvPp6Pq9L3NT0a9Rs%2BH5i4AEEe9gCuCxa4kSGy%2FvWZibW; VMhOIbxho_search_time=1576065710; _miucms_session=eee6c0622abd29c931709d7191ebe317; _miucms_session_gter=e5f80e0b26c692fa07b955c3857b5d80; Hm_lvt_4bd66cbe45a640b607fe46c48f658746=1576065653,1576077382,1576126419,1576126421; 4B5x_c0ae_sid=tnm4fh; 4B5x_c0ae_fid49=1576120563; 4B5x_c0ae_fid811=1576128945; 4B5x_c0ae_visitedfid=128D811D812D49; 4B5x_c0ae_sendmail=1; 4B5x_c0ae_lastact=1576136681%09forum.php%09forumdisplay; 4B5x_c0ae_forum_lastvisit=D_957_1576063866D_565_1576126441D_486_1576126509D_49_1576136376D_812_1576136386D_811_1576136401D_128_1576136681; Hm_lpvt_4bd66cbe45a640b607fe46c48f658746=1576136688'}\n",
    "\n",
    "for i in range(1,19):\n",
    "    url=base_url.format(i)\n",
    "    req=requests.get(url, headers=headers)\n",
    "    soup=BeautifulSoup(req.text,'lxml')\n",
    "    urllist1=[]\n",
    "    ai=soup.find_all(\"a\",class_=\"xst\")\n",
    "    for a in ai:\n",
    "        urllist1.append(a[\"href\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三.汇总五个模块的url库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36',\n",
    "         'Cookie':'4B5x_c0ae_saltkey=90SlvSJk; 4B5x_c0ae_lastvisit=1575463715; bdshare_firstime=1575467415257; 4B5x_c0ae_smile=1D1; _miucms_session_gter=d0facc83ccce085e2e85320391c14c1f; VMhOIbxho_search_time=1576228359; 4B5x_c0ae_ulastactivity=0e10w6kknfLw3ZX9YcOr3SpuaJtLuPL7A8viSlcWbACOy38yggLT; _miucms_session=57c526d7c8f6f2a451696e9e8a9363ea; Hm_lvt_4bd66cbe45a640b607fe46c48f658746=1576242984,1576299436,1576305412,1576305867; VMhOIbxho_member=3e339c1fbb7d25c04b482eb86ba50220; 4B5x_c0ae_sid=17BOS4; 4B5x_c0ae_miucms_uid=4009199; 4B5x_c0ae_onlineusernum=1458; 4B5x_c0ae_sendmail=1; 4B5x_c0ae_visitedfid=128D486D812D49; 4B5x_c0ae_checkpm=1; 4B5x_c0ae_home_diymode=1; 4B5x_c0ae_lastact=1576305999%09forum.php%09forumdisplay; 4B5x_c0ae_forum_lastvisit=D_957_1576063866D_565_1576126441D_811_1576149632D_1010_1576155336D_49_1576243004D_812_1576250197D_486_1576299501D_128_1576305999; Hm_lpvt_4bd66cbe45a640b607fe46c48f658746=1576306000'}\n",
    "\n",
    "base_url={0:'http://bbs.gter.net/forum.php?mod=forumdisplay&fid=128&orderby=dateline&typeid=1464&orderby=dateline&typeid=1464&filter=author&page={}',\n",
    "          1:'http://bbs.gter.net/forum.php?mod=forumdisplay&fid=812&typeid=995&orderby=dateline&filter=typeid&typeid=995&orderby=dateline&page={}',\n",
    "          2:'http://bbs.gter.net/forum.php?mod=forumdisplay&fid=486&orderby=dateline&typeid=992&filter=author&orderby=dateline&typeid=992&page={}',\n",
    "          3:'http://bbs.gter.net/forum.php?mod=forumdisplay&fid=811&orderby=dateline&typeid=994&filter=author&orderby=dateline&typeid=994&page={}',\n",
    "          4:'http://bbs.gter.net/forum.php?mod=forumdisplay&fid=49&orderby=dateline&typeid=158&filter=author&orderby=dateline&typeid=158&page={}'}\n",
    "\n",
    "number=[13,27,50,134,120]\n",
    "\n",
    "name=['Aus','Sing','UK','HK','USA']\n",
    "\n",
    "URLLIST={0:[],1:[],2:[],3:[],4:[]}\n",
    "\n",
    "for i in range(0,5):\n",
    "    url0=base_url[i]\n",
    "    \n",
    "    for j in range(1,number[i]):\n",
    "        url=url0.format(j)\n",
    "        re=[]  #Response库\n",
    "        req=requests.get(url,headers=headers)\n",
    "        re.append(req)\n",
    "        \n",
    "        for r in re:\n",
    "            soup=[]  #Soup解析库\n",
    "            soup0=BeautifulSoup(r.text,'lxml')\n",
    "            soup.append(soup0)\n",
    "            \n",
    "            for soup0 in soup:\n",
    "                ai=soup0.find_all(\"a\",class_=\"xst\")\n",
    "                \n",
    "                for a in ai:\n",
    "                    URLLIST[i].append(a[\"href\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "四.将获取的url库保存，以便后续利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-bbc392789514>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mURLLIST\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    text=pd.DataFrame(data=URLLIST[i])\n",
    "    text.to_csv('{}.csv'.format(name[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "五.利用正则表达式获取url中的id进行汇总，以便后续键值对应连接，并将获取的url库保存，以便后续利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'URLLIST' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d66d6b9445f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mURLLIST\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mid0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\d+'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mURLLIST\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'URLLIST' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "id=[[],[],[],[],[]]\n",
    "for i in range(0,5):\n",
    "    for j in range(0,len(URLLIST[i])):\n",
    "        id0=re.findall('\\d+',URLLIST[i][j])\n",
    "        id[i].append(id0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    id0=pd.DataFrame(data=id[i])\n",
    "    id0.to_csv('{}id.csv'.format(name[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "五个板块分别为：澳洲、新加坡、英国、香港、美国"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分别共有19、66、97、333、466页offer数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对其中入学年份进行筛选，选择2018、2019、2020入学年份的数据，分别有13、27、50、134、120页数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分别共爬取420、910、1715、4655、4165申请人次的url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number=[13,27,50,134,120]\n",
    "print(len(URLLIST[0]))\n",
    "print(len(URLLIST[1]))\n",
    "print(len(URLLIST[2]))\n",
    "print(len(URLLIST[3]))\n",
    "print(len(URLLIST[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=[]\n",
    "for i in range(0,5):\n",
    "    for url in URLLIST[i]:\n",
    "        num.append(numofoffer(url))\n",
    "        a=max(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxnum=[13,9,18,11,22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(0,5):\n",
    "    for i in range(0,len(URLLIST[k])):\n",
    "        offer=pd.DataFrame(offerextract(URLLIST[i])).T\n",
    "        j=id[k][i]\n",
    "        offer.to_csv('Offer\\{}.csv'.format(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 具体信息界面的抓取——以一页为例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 页面处理：计算统一用户的offer个数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 先以一个网页为例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义函数numofoffer用来计算一个url界面中的offer个数，便于offer信息的爬取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "\n",
    "headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36',\n",
    "         'Cookie':'4B5x_c0ae_saltkey=90SlvSJk; 4B5x_c0ae_lastvisit=1575463715; bdshare_firstime=1575467415257; 4B5x_c0ae_smile=1D1; 4B5x_c0ae_ulastactivity=c423cAryvPp6Pq9L3NT0a9Rs%2BH5i4AEEe9gCuCxa4kSGy%2FvWZibW; VMhOIbxho_search_time=1576065710; _miucms_session=eee6c0622abd29c931709d7191ebe317; _miucms_session_gter=e5f80e0b26c692fa07b955c3857b5d80; Hm_lvt_4bd66cbe45a640b607fe46c48f658746=1576065653,1576077382,1576126419,1576126421; 4B5x_c0ae_sid=tnm4fh; 4B5x_c0ae_fid49=1576120563; 4B5x_c0ae_fid811=1576128945; 4B5x_c0ae_visitedfid=128D811D812D49; 4B5x_c0ae_sendmail=1; 4B5x_c0ae_lastact=1576136681%09forum.php%09forumdisplay; 4B5x_c0ae_forum_lastvisit=D_957_1576063866D_565_1576126441D_486_1576126509D_49_1576136376D_812_1576136386D_811_1576136401D_128_1576136681; Hm_lpvt_4bd66cbe45a640b607fe46c48f658746=1576136688'}\n",
    "\n",
    "#Eg.目标url\n",
    "url='http://bbs.gter.net/forum.php?mod=viewthread&tid=2298782&extra=page%3D1%26filter%3Dauthor%26orderby%3Ddateline%26typeid%3D995%26typeid%3D995%26orderby%3Ddateline'\n",
    "\n",
    "def numofoffer(url):\n",
    "    \"\"\"计算各个页面中的offer个数 以确定offer节点数\"\"\"\n",
    "    r=requests.get(url,headers=headers)\n",
    "    soup=BeautifulSoup(r.text,'lxml')\n",
    "    offerlist=soup.select('table[summary*=\"offer\"]')  \n",
    "    #css选择器   [attribute*=value]\tEg. a[src*=\"abc\"]\t选择其 src 属性中包含 \"abc\" 子串的每个 <a> 元素\n",
    "    return(len(offerlist))\n",
    "    #计算筛选列表中符合条件的offer节点个数 即实现offer个数的计算\n",
    "\n",
    "numofoffer(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息总体包括两部分：offer信息和个人信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一.获取offer相关信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "\n",
    "infolist=['申请学校','学位','专业','申请结果','入学年份','入学学期',\n",
    "          '通知时间','语言成绩','标化成绩','本科学校档次','本科专业',\n",
    "          '本科成绩和算法、排名','其他说明']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义offer信息抓取函数offerextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def offerextract(url):\n",
    "    \n",
    "    offer={}\n",
    "    for i in range(0,numofoffer(url)):\n",
    "        offer[i]=[]\n",
    "        for j in range(0,7):\n",
    "            offer[i].append([])\n",
    "            \n",
    "    m=numofoffer(url)\n",
    "    \n",
    "    r=requests.get(url,headers=headers)\n",
    "    html=etree.HTML(r.text)\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup=BeautifulSoup(r.text,'lxml')\n",
    "    table=soup.find_all('table',class_=\"cgtl mbm\")[0:m]\n",
    "    \n",
    "    requests.DEFAULT_RETRIES =5\n",
    "    s=requests.session()\n",
    "    s.keep_alive=False\n",
    "    \n",
    "    for j in range(0,m):\n",
    "        tdt=table[j].find_all('td')\n",
    "        for k in range(0,7):\n",
    "            offer[j][k]=tdt[k].get_text().strip()\n",
    "    return offer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['The University of Sydney',\n",
       "  'MA',\n",
       "  'Urban Design',\n",
       "  'offer',\n",
       "  '2020',\n",
       "  'Spring',\n",
       "  '2019-09-17'],\n",
       " 1: ['RMIT University',\n",
       "  'MS',\n",
       "  'Urban Design',\n",
       "  'offer',\n",
       "  '2020',\n",
       "  'Spring',\n",
       "  '2019-09-20'],\n",
       " 2: ['The University of Adelaide',\n",
       "  'MA',\n",
       "  'Master of Planning(urban design)/Master of Landscape Architecture',\n",
       "  'AD小奖',\n",
       "  '2020',\n",
       "  'Spring',\n",
       "  '2019-09-30'],\n",
       " 3: ['The University of New South Wales',\n",
       "  'MA',\n",
       "  'Master of Urban Development(Design)',\n",
       "  'offer',\n",
       "  '2020',\n",
       "  'Summer',\n",
       "  '2019-10-03'],\n",
       " 4: ['The University of Queensland',\n",
       "  'MA',\n",
       "  'Urban Design',\n",
       "  'AD无奖',\n",
       "  '2020',\n",
       "  'Summer',\n",
       "  '2019-11-05']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url1='http://bbs.gter.net/forum.php?mod=viewthread&tid=2293804&extra=page%3D1%26filter%3Dauthor%26orderby%3Ddateline%26typeid%3D1464%26typeid%3D1464%26orderby%3Ddateline'\n",
    "offerextract(url1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运用已保存的url库进行批量获取,并保存至Offer文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offer1(list):\n",
    "    \"\"\"获取列表各url中的offer情况\"\"\"\n",
    "    for i in range(0,len(list)):\n",
    "        offer=pd.DataFrame(offerextract(list[i])).T\n",
    "        offer.to_excel('Offer11\\{}.xlsx'.format(id1[i]))\n",
    "    return\n",
    "\n",
    "def offer2(list):\n",
    "    \"\"\"获取列表各url中的offer情况\"\"\"\n",
    "    for i in range(0,len(list)):\n",
    "        offer=pd.DataFrame(offerextract(list[i])).T\n",
    "        offer.to_excel('Offer2\\{}.xlsx'.format(id2[i]))\n",
    "    return\n",
    "\n",
    "def offer3(list):\n",
    "    \"\"\"获取列表各url中的offer情况\"\"\"\n",
    "    for i in range(0,len(list)):\n",
    "        offer=pd.DataFrame(offerextract(list[i])).T\n",
    "        offer.to_excel('Offer3\\{}.xlsx'.format(id3[i]))\n",
    "    return\n",
    "\n",
    "def offer4(list):\n",
    "    \"\"\"获取列表各url中的offer情况\"\"\"\n",
    "    for i in range(0,len(list)):\n",
    "        offer=pd.DataFrame(offerextract(list[i])).T\n",
    "        offer.to_excel('Offer4\\{}.xlsx'.format(id4[i]))\n",
    "    return\n",
    "\n",
    "def offer5(list):\n",
    "    \"\"\"获取列表各url中的offer情况\"\"\"\n",
    "    for i in range(0,len(list)):\n",
    "        offer=pd.DataFrame(offerextract(list[i])).T\n",
    "        offer.to_excel('Offer5\\{}.xlsx'.format(id5[i]))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer1(aus);offer2(sing);offer3(uk);offer4(hk);offer5(usa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以一个url进行提取示例展示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The University of Melbourne 墨尔本大学</td>\n",
       "      <td>LLM</td>\n",
       "      <td>Law 法律</td>\n",
       "      <td>AD无奖</td>\n",
       "      <td>2020</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2019-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Chinese University of Hong Kong 香港中文大学</td>\n",
       "      <td>LLM</td>\n",
       "      <td>HK:International economic law</td>\n",
       "      <td>AD无奖</td>\n",
       "      <td>2020</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2019-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Chinese University of Hong Kong 香港中文大学</td>\n",
       "      <td>LLM</td>\n",
       "      <td>HK:Chinese business law</td>\n",
       "      <td>AD无奖</td>\n",
       "      <td>2020</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2019-12-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0    1  \\\n",
       "0           The University of Melbourne 墨尔本大学  LLM   \n",
       "1  The Chinese University of Hong Kong 香港中文大学  LLM   \n",
       "2  The Chinese University of Hong Kong 香港中文大学  LLM   \n",
       "\n",
       "                               2     3     4     5           6  \n",
       "0                         Law 法律  AD无奖  2020  Fall  2019-09-12  \n",
       "1  HK:International economic law  AD无奖  2020  Fall  2019-12-10  \n",
       "2        HK:Chinese business law  AD无奖  2020  Fall  2019-12-10  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url2='http://bbs.gter.net/forum.php?mod=viewthread&tid=2292596&extra=page%3D1%26filter%3Dauthor%26orderby%3Ddateline%26typeid%3D1464%26typeid%3D1464%26orderby%3Ddateline'\n",
    "df=pd.DataFrame(offerextract(url2))\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 二.获取个人信息部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "个人信息总体分为以下几个方面，其中我将语言成绩分开为两个内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义个人信息爬取的infoextract函数，爬取过程主要是要判断非空，再在非空的情况下填入节点内容，否则填入空格占位。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "TEXT=[\"TOEFL:\",\"IELTS\",\"GRE:\",\"GMAT\",\n",
    "      \"本科学校档次:\",\"本科专业:\",\"本科成绩和算法、排名:\",\n",
    "      \"研究生学校档次:\",\"研究生专业:\",\"研究生成绩和算法、排名:\",\n",
    "      \"其他说明:\"]\n",
    "    headers={'User-Agent':'ozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36','Cookie':'44B5x_c0ae_saltkey=90SlvSJk; 4B5x_c0ae_lastvisit=1575463715; bdshare_firstime=1575467415257; 4B5x_c0ae_smile=1D1; _miucms_session_gter=d0facc83ccce085e2e85320391c14c1f; VMhOIbxho_search_time=1576228359; 4B5x_c0ae_home_diymode=1; 4B5x_c0ae_secqaaS06oRKy0=d5d7zeBA%2FCHMjPJWKHVIVnv6BF3RoPVRdZ%2F7Euwk%2BNea4PJoln%2Bh7r5Z0iii8GL%2Bnxs3AWwKonblFPfPwkfqt6upq8SU7OSa9UY9r1J8yDYxQHqY2kkzdBQx; 4B5x_c0ae_seccodeS06oRKy0=2686AgdnAPFfUJUWNiPcpDRzve18CAxHFk81GkdI7qoKsfE9CGU6%2FGMqlBhXppCxRVgopQClsk7JAW7Nwts; 4B5x_c0ae_secqaaSIeoks60=2b50f7kALTxFFd%2BtoBO9YoZW3ng8wl8GLcA1PKUtCKdjKvbK9B5E9AeCUBHQ9nQ4NWU80Annw%2BIkczFG6MVUz39%2FqCLRul77ZStbWiR2sRXydFk4KWbFUfWh; 4B5x_c0ae_seccodeSIeoks60=1895gxGwMxXl2Ts4jIHMMKiRsQwiRbKlWoa0I5xWdEodohCnXLQwp9drj57JRtY1xSiJShkYrkGzH1FLbeM; 4B5x_c0ae_secqaaSXNFgPi0=b89cye%2FKR847InUUApiMHvDflBxM5QhF87gPAXfPy0ZrxYwzC2fbUqaa8WaBDtxKl3o69w%2BSjaqA4jCW1%2BBvAudSg9wtgR%2FwAUZ0DMVZwZXk8xmwR3MVhTYe; 4B5x_c0ae_seccodeSXNFgPi0=c80bEsdhn9rfAIDfWE48ajfAu5PFy62iFUWCTsNFH%2BWxlygJ%2B%2F5OQq0lB%2FFNsta2AGrbauV9Su8GjRf9WVE; 4B5x_c0ae_ulastactivity=1ccarGBHxYemDnNe5WKS91JFxceextzXoP5YAqw8h2FY%2FXeHSzAJ; _miucms_session=ae1831f5b8269d6a5c7f841faf9d59a3; VMhOIbxho_member=6d06417529b3d01febf59df4aaa98cdd; 4B5x_c0ae_miucms_uid=4009199; 4B5x_c0ae_secqaaS7GAFJG0=64282dNfe%2FVBtWAnsdzjBMCyfC5kMGfaITOkYPqpdosk%2FohuQnkJ8XIBVbkvNk%2FnZHpNUryCPifirrFbOmdyhFpwH7eO%2BAfLaTEEBiWC%2BD3dxWDsKBZKGaXe; 4B5x_c0ae_seccodeS7GAFJG0=ac8cH0ZI9ApWA73RjqCrlbvLOMXx0CFEtAAedZXS2zEukIaEF%2FE%2BsTw723w%2BpIhWsx3vjvUgxPWDpBlGrPY; 4B5x_c0ae_secqaaSgL5K3F0=faf5j0XKFhVc0wMwL0ZWagmgDpG4KcWFThn65%2BAjBH0tv4dJZWar93HyhZbfkHKhoGCPguoUFIrKnITrci4tINf9tKHgpGq9UYQ1j5hxBo7pVpmF5oRhAWc5; 4B5x_c0ae_seccodeSgL5K3F0=07366DeiZfNe2Y34WSeOWWSj5YvlnlYYz9zSZZ1%2FMJYofqKESyFfckTFvg1p0rSwZ4ze2iR7D9AO5Hj9JaY; 4B5x_c0ae_secqaaSNmLoL00=d07al%2FmD3OnAjYuFjbreZj0IlzIbphn4pewmdAxTKUjHV3QK0cZ9IobBWs1U%2FCEx2coBVslRMsYXJPuBVWKcuUkVEAK2tP%2Bql1gJsbfdqX%2BafIU4KalQpGNI; 4B5x_c0ae_seccodeSNmLoL00=0eaaVpxSgvYFnwx5SKOAtkTSEHGZVKdrAxLjFzGR05bUo%2F%2BEckA8heTAbYbfdLcaVRCJDfpj6kw%2BmnOjGRQ; 4B5x_c0ae_secqaaSThcwH60=bc347mMqDFKRSUK2P3nlpr1yQ3qAfmjTAf8q8UFd7ltREsnJsWNJdxDsIaelZG0%2Bnuke%2B8osPm547DrorarUCLSCD2aKJWCMzoIWnxP9sEe%2BZ8rBieEhimIa; 4B5x_c0ae_seccodeSThcwH60=b94f3ER1UoBoILbKc4We%2B%2FSNUOa%2BdG4lCYk6v3xmZHBVXhdsrlJiseF%2FnLjJxS%2F5PRdAojY7QSlixSnZdc0; 4B5x_c0ae_secqaaS0pXfft0=14fbT%2BCqj8nZ657vi8mXARpvSRqLNTY9Fi3nnDt%2BEDcyEI9HYAAoBrBc2VacQriWr%2FsHvb5Q7kHrtHWXh%2Fyx5vj5AVRh8xCoaEcDtDX4wLwJux%2FUMJdiAkGr; 4B5x_c0ae_seccodeS0pXfft0=a2f2RZwX0Z0CxOhXGiqinKCnEs6eRAgorz7OcGQjtxQQnOYyayN2PaN6GcVY3dD3TJV7873F6yB5osV40p0; 4B5x_c0ae_secqaaS3JC3M40=6ebf0zn0F9BGYzzHlC9NLxTq%2F1L%2FKZeRLD94%2FZTE0xbO4MXRjo7YtMvR8utL5La%2BeOo09L%2B46hrjri8BuhCw3u6O5zp3MQljyeNFWXaT2kv0JVYf6ZpBT9dz; 4B5x_c0ae_seccodeS3JC3M40=f229fgqwyPCBuMzFisI6W0FrrQbUGow3NRosOP5gSpEcVy5Y%2BSfFUSZNFJXZ75gpFkNn3aJX4gXxk1amDL8; Hm_lvt_4bd66cbe45a640b607fe46c48f658746=1576305412,1576305867,1576321094,1576331938; 4B5x_c0ae_visitedfid=49D811D997D486; 4B5x_c0ae_checkpm=1; 4B5x_c0ae_sendmail=1; 4B5x_c0ae_sid=TOq3sD; 4B5x_c0ae_lastact=1576331952%09forum.php%09forumdisplay; 4B5x_c0ae_forum_lastvisit=D_957_1576063866D_565_1576126441D_1010_1576155336D_128_1576306226D_812_1576321887D_486_1576321899D_811_1576325603D_49_1576331952; Hm_lpvt_4bd66cbe45a640b607fe46c48f658746=1576331955'}    \n",
    "def infoextract(url):\n",
    "    \"\"\"页面获取个人信息\"\"\"\n",
    "    INFODICT={0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[],9:[],10:[]}\n",
    "    r=requests.get(url,headers=headers)\n",
    "    requests.DEFAULT_RETRIES =5\n",
    "    s=requests.session()\n",
    "    s.keep_alive=False\n",
    "    \n",
    "    html=etree.HTML(r.text)\n",
    "    if html.xpath('//th[text()=\"TOEFL:\"]')==[]:\n",
    "        INFODICT[0].append(\" \")\n",
    "    else:\n",
    "        INFODICT[0].append(html.xpath('normalize-space(//th[text()=\"TOEFL:\"]/following::*[1]/text())'))\n",
    "        \n",
    "    if html.xpath('//th[text()=\"IELTS:\"]')==[]:\n",
    "        INFODICT[1].append(\" \")\n",
    "    else:\n",
    "        INFODICT[1].append(html.xpath('normalize-space(//th[text()=\"IELTS:\"]/following::*[1]/text())'))\n",
    "                       \n",
    "    if html.xpath('//th[text()=\"GRE:\"]')==[] or html.xpath('//th[text()=\"GMAT:\"]') == []:\n",
    "        INFODICT[2].append(\" \")\n",
    "    else:\n",
    "        INFODICT[2].append(html.xpath('normalize-space(//th[text()=\"GRE:\"]/following::*[1]/text())'))\n",
    "\n",
    "    if html.xpath('//th[text()=\"GMAT:\"]') == []:\n",
    "        INFODICT[3].append(\" \")\n",
    "    else:\n",
    "        INFODICT[3].append(html.xpath('normalize-space(//th[text()=\"GMAT:\"]/following::*[1]/text())'))\n",
    "                       \n",
    "    if html.xpath('//th[text()=\"本科学校档次:\"]')==[]:\n",
    "        INFODICT[4].append(\" \")\n",
    "    else:\n",
    "        INFODICT[4].append(html.xpath('normalize-space(//th[text()=\"本科学校档次:\"]/following::*[1]/text())'))\n",
    "                       \n",
    "    if html.xpath('//th[text()=\"本科专业:\"]')==[]:\n",
    "        INFODICT[5].append(\" \")\n",
    "    else:\n",
    "        INFODICT[5].append(html.xpath('normalize-space(//th[text()=\"本科专业:\"]/following::*[1]/text())'))\n",
    "            \n",
    "    if html.xpath('//th[text()=\"本科成绩和算法、排名:\"]')==[]:\n",
    "        INFODICT[6].append(\" \")\n",
    "    else:\n",
    "        INFODICT[6].append(html.xpath('normalize-space(//th[text()=\"本科成绩和算法、排名:\"]/following::*[1]/text())'))\n",
    "                       \n",
    "    if html.xpath('//th[text()=\"研究生学校档次:\"]')==[]:\n",
    "        INFODICT[7].append(\" \")\n",
    "    else:\n",
    "        INFODICT[7].append(html.xpath('normalize-space(//th[text()=\"研究生学校档次:\"]/following::*[1]/text())'))\n",
    "    \n",
    "    if html.xpath('//th[text()=\"研究生专业:\"]')==[]:\n",
    "        INFODICT[8].append(\" \")\n",
    "    else:\n",
    "        INFODICT[8].append(html.xpath('normalize-space(//th[text()=\"研究生专业:\"]/following::*[1]/text())'))\n",
    "    if html.xpath('//th[text()=\"研究生成绩和算法、排名:\"]')==[]:\n",
    "        INFODICT[9].append(\" \")\n",
    "    else:\n",
    "        INFODICT[9].append(html.xpath('normalize-space(//th[text()=\"研究生成绩和算法、排名:\"]/following::*[1]/text())'))\n",
    "    if html.xpath('//th[text()=\"其他说明:\"]')==[]:\n",
    "        INFODICT[10].append(\" \")\n",
    "    else:\n",
    "        INFODICT[10].append(html.xpath('normalize-space(//th[text()=\"其他说明:\"]/following::*[1]/text())'))\n",
    "    \n",
    "    \n",
    "    time.sleep(3)\n",
    "    global DICT\n",
    "    DICT=[]\n",
    "    for i in range(0,11):\n",
    "        DICT.append(INFODICT[i][0])\n",
    "    return DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一开始尝试的是将一个模块的url读取后全部汇总成一张信息表，但是这样太慢了，而且总是卡死"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "df_empty=pd.DataFrame(columns=range(0,11))\n",
    "\n",
    "for j in range(0,910):\n",
    "    headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36',\n",
    "             'Cookie':'4B5x_c0ae_saltkey=90SlvSJk; 4B5x_c0ae_lastvisit=1575463715; bdshare_firstime=1575467415257; 4B5x_c0ae_smile=1D1; _miucms_session_gter=d0facc83ccce085e2e85320391c14c1f; VMhOIbxho_search_time=1576228359; 4B5x_c0ae_home_diymode=1; 4B5x_c0ae_secqaaS06oRKy0=d5d7zeBA%2FCHMjPJWKHVIVnv6BF3RoPVRdZ%2F7Euwk%2BNea4PJoln%2Bh7r5Z0iii8GL%2Bnxs3AWwKonblFPfPwkfqt6upq8SU7OSa9UY9r1J8yDYxQHqY2kkzdBQx; 4B5x_c0ae_seccodeS06oRKy0=2686AgdnAPFfUJUWNiPcpDRzve18CAxHFk81GkdI7qoKsfE9CGU6%2FGMqlBhXppCxRVgopQClsk7JAW7Nwts; 4B5x_c0ae_secqaaSIeoks60=2b50f7kALTxFFd%2BtoBO9YoZW3ng8wl8GLcA1PKUtCKdjKvbK9B5E9AeCUBHQ9nQ4NWU80Annw%2BIkczFG6MVUz39%2FqCLRul77ZStbWiR2sRXydFk4KWbFUfWh; 4B5x_c0ae_seccodeSIeoks60=1895gxGwMxXl2Ts4jIHMMKiRsQwiRbKlWoa0I5xWdEodohCnXLQwp9drj57JRtY1xSiJShkYrkGzH1FLbeM; 4B5x_c0ae_secqaaSXNFgPi0=b89cye%2FKR847InUUApiMHvDflBxM5QhF87gPAXfPy0ZrxYwzC2fbUqaa8WaBDtxKl3o69w%2BSjaqA4jCW1%2BBvAudSg9wtgR%2FwAUZ0DMVZwZXk8xmwR3MVhTYe; 4B5x_c0ae_seccodeSXNFgPi0=c80bEsdhn9rfAIDfWE48ajfAu5PFy62iFUWCTsNFH%2BWxlygJ%2B%2F5OQq0lB%2FFNsta2AGrbauV9Su8GjRf9WVE; 4B5x_c0ae_ulastactivity=1ccarGBHxYemDnNe5WKS91JFxceextzXoP5YAqw8h2FY%2FXeHSzAJ; _miucms_session=ae1831f5b8269d6a5c7f841faf9d59a3; VMhOIbxho_member=6d06417529b3d01febf59df4aaa98cdd; 4B5x_c0ae_miucms_uid=4009199; 4B5x_c0ae_secqaaS7GAFJG0=64282dNfe%2FVBtWAnsdzjBMCyfC5kMGfaITOkYPqpdosk%2FohuQnkJ8XIBVbkvNk%2FnZHpNUryCPifirrFbOmdyhFpwH7eO%2BAfLaTEEBiWC%2BD3dxWDsKBZKGaXe; 4B5x_c0ae_seccodeS7GAFJG0=ac8cH0ZI9ApWA73RjqCrlbvLOMXx0CFEtAAedZXS2zEukIaEF%2FE%2BsTw723w%2BpIhWsx3vjvUgxPWDpBlGrPY; 4B5x_c0ae_secqaaSgL5K3F0=faf5j0XKFhVc0wMwL0ZWagmgDpG4KcWFThn65%2BAjBH0tv4dJZWar93HyhZbfkHKhoGCPguoUFIrKnITrci4tINf9tKHgpGq9UYQ1j5hxBo7pVpmF5oRhAWc5; 4B5x_c0ae_seccodeSgL5K3F0=07366DeiZfNe2Y34WSeOWWSj5YvlnlYYz9zSZZ1%2FMJYofqKESyFfckTFvg1p0rSwZ4ze2iR7D9AO5Hj9JaY; 4B5x_c0ae_secqaaSNmLoL00=d07al%2FmD3OnAjYuFjbreZj0IlzIbphn4pewmdAxTKUjHV3QK0cZ9IobBWs1U%2FCEx2coBVslRMsYXJPuBVWKcuUkVEAK2tP%2Bql1gJsbfdqX%2BafIU4KalQpGNI; 4B5x_c0ae_seccodeSNmLoL00=0eaaVpxSgvYFnwx5SKOAtkTSEHGZVKdrAxLjFzGR05bUo%2F%2BEckA8heTAbYbfdLcaVRCJDfpj6kw%2BmnOjGRQ; 4B5x_c0ae_secqaaSThcwH60=bc347mMqDFKRSUK2P3nlpr1yQ3qAfmjTAf8q8UFd7ltREsnJsWNJdxDsIaelZG0%2Bnuke%2B8osPm547DrorarUCLSCD2aKJWCMzoIWnxP9sEe%2BZ8rBieEhimIa; 4B5x_c0ae_seccodeSThcwH60=b94f3ER1UoBoILbKc4We%2B%2FSNUOa%2BdG4lCYk6v3xmZHBVXhdsrlJiseF%2FnLjJxS%2F5PRdAojY7QSlixSnZdc0; 4B5x_c0ae_secqaaS0pXfft0=14fbT%2BCqj8nZ657vi8mXARpvSRqLNTY9Fi3nnDt%2BEDcyEI9HYAAoBrBc2VacQriWr%2FsHvb5Q7kHrtHWXh%2Fyx5vj5AVRh8xCoaEcDtDX4wLwJux%2FUMJdiAkGr; 4B5x_c0ae_seccodeS0pXfft0=a2f2RZwX0Z0CxOhXGiqinKCnEs6eRAgorz7OcGQjtxQQnOYyayN2PaN6GcVY3dD3TJV7873F6yB5osV40p0; 4B5x_c0ae_secqaaS3JC3M40=6ebf0zn0F9BGYzzHlC9NLxTq%2F1L%2FKZeRLD94%2FZTE0xbO4MXRjo7YtMvR8utL5La%2BeOo09L%2B46hrjri8BuhCw3u6O5zp3MQljyeNFWXaT2kv0JVYf6ZpBT9dz; 4B5x_c0ae_seccodeS3JC3M40=f229fgqwyPCBuMzFisI6W0FrrQbUGow3NRosOP5gSpEcVy5Y%2BSfFUSZNFJXZ75gpFkNn3aJX4gXxk1amDL8; Hm_lvt_4bd66cbe45a640b607fe46c48f658746=1576305412,1576305867,1576321094,1576331938; 4B5x_c0ae_visitedfid=49D811D997D486; 4B5x_c0ae_checkpm=1; 4B5x_c0ae_sendmail=1; 4B5x_c0ae_sid=TOq3sD; 4B5x_c0ae_lastact=1576331952%09forum.php%09forumdisplay; 4B5x_c0ae_forum_lastvisit=D_957_1576063866D_565_1576126441D_1010_1576155336D_128_1576306226D_812_1576321887D_486_1576321899D_811_1576325603D_49_1576331952; Hm_lpvt_4bd66cbe45a640b607fe46c48f658746=1576331955'}\n",
    "    url=sing[j]\n",
    "    r=requests.get(url,headers=headers)\n",
    "    soup=BeautifulSoup(r.text,'lxml')\n",
    "    html=etree.HTML(r.text)\n",
    "    df_empty.loc[j]=infoextract(url)\n",
    "    \n",
    "    requests.DEFAULT_RETRIES = 5\n",
    "    s=requests.session()\n",
    "    s.keep_alive=False\n",
    "        \n",
    "\n",
    "df_empty.replace(' ',np.nan)\n",
    "df_empty.to_csv('Singsummary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后来选择批量读取后再进行拼接为一个文件，效率高了很多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "singurl = list(reader(open('Sing.csv')))\n",
    "ukurl = list(reader(open('UK.csv')))\n",
    "hkurl = list(reader(open('HK.csv')))\n",
    "usaurl = list(reader(open('USA.csv')))\n",
    "\n",
    "ausid = list(reader(open('Ausid.csv')))\n",
    "singid = list(reader(open('Singid.csv')))\n",
    "ukid = list(reader(open('UKid.csv')))\n",
    "hkid = list(reader(open('HKid.csv')))\n",
    "usaid = list(reader(open('USAid.csv')))\n",
    "\n",
    "from itertools import chain\n",
    "sing=list(chain.from_iterable(singurl))\n",
    "uk=list(chain.from_iterable(ukurl))\n",
    "hk=list(chain.from_iterable(hkurl))\n",
    "usa=list(chain.from_iterable(usaurl))\n",
    "id1 = list(chain.from_iterable(ausid))\n",
    "id2 = list(chain.from_iterable(singid))\n",
    "id3 = list(chain.from_iterable(ukid))\n",
    "id4 = list(chain.from_iterable(hkid))\n",
    "id5 = list(chain.from_iterable(usaid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取已经保存好的url库及id库，定义info函数，进行个人信息的批量汇总、存储并以id命名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info1(list):\n",
    "    \"\"\"获取列表各url中的个人情况\"\"\"\n",
    "    for i in range(0,len(list)):\n",
    "        \n",
    "        info=pd.DataFrame(infoextract(list[i])).T\n",
    "        info.to_excel('info1\\{}.xlsx'.format(id1[i]))\n",
    "    return\n",
    "\n",
    "def info2(list):\n",
    "    \"\"\"获取列表各url中的个人情况\"\"\"\n",
    "    for i in range(0,len(list)):\n",
    "        \n",
    "        info=pd.DataFrame(infoextract(list[i])).T\n",
    "        info.to_excel('info21\\{}.xlsx'.format(id2[i]))\n",
    "    return\n",
    "\n",
    "def info3(list):\n",
    "    \"\"\"获取列表各url中的个人情况\"\"\"\n",
    "    for i in range(0,len(list)):\n",
    "        \n",
    "        info=pd.DataFrame(infoextract(list[i])).T\n",
    "        info.to_excel('info3\\{}.xlsx'.format(id3[i]))\n",
    "    return\n",
    "\n",
    "def info4(list):\n",
    "    \"\"\"获取列表各url中的个人情况\"\"\"\n",
    "    for i in range(663,len(list)):\n",
    "        \n",
    "        info=pd.DataFrame(infoextract(list[i])).T\n",
    "        info.to_excel('info4\\{}.xlsx'.format(id4[i]))\n",
    "    return\n",
    "\n",
    "def info5(list):\n",
    "    \"\"\"获取列表各url中的个人情况\"\"\"\n",
    "    for i in range(0,len(list)):\n",
    "        \n",
    "        info=pd.DataFrame(infoextract(list[i])).T\n",
    "        info.to_excel('info5\\{}.xlsx'.format(id5[i]))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info1(aus);info2(sing);info3(uk);info4(hk);info5(usa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 爬取结果："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "澳洲\\新加坡\\英国\\香港\\美国五个板块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "共获取申请人420\\910\\1713\\4646\\4165人次 与获取的url数吻合 匹配程度较好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "共获取Offer420\\910\\1427\\3960\\3807份Offer汇总"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Offer方面有部分缺失 应该是响应时间过长自动跳过导致缺失"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
